{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Tuple, List, Dict, Any\n",
    "import functools\n",
    "import time\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "# predictably random behavior\n",
    "RANDOM_KEY = jax.random.PRNGKey(42)\n",
    "\n",
    "# what is this being run on?\n",
    "print(f\"jax.device_count() {jax.device_count()}\")\n",
    "print(f\"jax.local_device_count() {jax.local_device_count()}\")\n",
    "for i, device in enumerate(jax.devices()):\n",
    "    print(f\" --- Found device: {i} \")\n",
    "    print(f\"\\t device_kind: {device.device_kind}\")\n",
    "    print(f\"\\t platform: {device.platform}\")\n",
    "    print(f\"\\t host_id: {device.host_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_layer_params(\n",
    "    input_size: int, output_size: int, random_key: jnp.DeviceArray, scale: float = 1e-2\n",
    ") -> Tuple[jnp.DeviceArray]:\n",
    "    \"\"\"Creates a single layer of an MLP.\"\"\"\n",
    "    w_key, b_key = jax.random.split(random_key)\n",
    "    return scale * jax.random.normal(\n",
    "        w_key, (output_size, input_size)\n",
    "    ), scale * jax.random.normal(b_key, (output_size,))\n",
    "\n",
    "\n",
    "def init_network_params(\n",
    "    layer_sizes: List[int], random_key: jnp.DeviceArray\n",
    ") -> List[Tuple[jnp.DeviceArray]]:\n",
    "    \"\"\"Initialize a N-layer MLP.\"\"\"\n",
    "    layer_keys = jax.random.split(random_key, len(layer_sizes))\n",
    "    network_params: List[Tuple[jnp.DeviceArray]] = []\n",
    "    for in_size, out_size, key in zip(layer_sizes[:-1], layer_sizes[1:], layer_keys):\n",
    "        network_params.append(random_layer_params(in_size, out_size, key))\n",
    "    return network_params\n",
    "\n",
    "\n",
    "def relu(x: jnp.DeviceArray) -> jnp.DeviceArray:\n",
    "    \"\"\"Rectified-Linear Unit.\"\"\"\n",
    "    return jnp.maximum(0, x)\n",
    "\n",
    "\n",
    "@functools.partial(jax.vmap, in_axes=(None, 0))\n",
    "def predict(\n",
    "    params: List[Tuple[jnp.DeviceArray]],\n",
    "    image: jnp.DeviceArray,\n",
    ") -> jnp.DeviceArray:\n",
    "    \"\"\"Forward prediction with an MLP denoted by params.\"\"\"\n",
    "    x: jnp.DeviceArray = image\n",
    "    for w, b in params[:-1]:\n",
    "        x = relu(jnp.dot(w, x) + b)\n",
    "    # last layer has no activation\n",
    "    last_w, last_b = params[-1]\n",
    "    x = relu(jnp.dot(last_w, x) + last_b)\n",
    "    # log of the sum of exponentials of input elements\n",
    "    return x - jax.scipy.special.logsumexp(x)\n",
    "\n",
    "\n",
    "def one_hot(\n",
    "    x: jnp.DeviceArray,\n",
    "    k: int,\n",
    "    dtype=jnp.float32,\n",
    ") -> jnp.DeviceArray:\n",
    "    \"\"\"One-hot encoding of size k.\"\"\"\n",
    "    return jnp.array(x[:, None] == jnp.arange(k), dtype)\n",
    "\n",
    "\n",
    "def accuracy(\n",
    "    params: List[Tuple[jnp.DeviceArray]],\n",
    "    images: jnp.DeviceArray,\n",
    "    targets: jnp.DeviceArray,\n",
    ") -> jnp.DeviceArray:\n",
    "    \"\"\"Accuracy of one-hot image prediction compared to target.\"\"\"\n",
    "    target_class = jnp.argmax(targets, axis=1)\n",
    "    predict_class = jnp.argmax(predict(params, images), axis=1)\n",
    "    return jnp.mean(predict_class == target_class)\n",
    "\n",
    "\n",
    "def loss(\n",
    "    params: List[Tuple[jnp.DeviceArray]],\n",
    "    images: jnp.DeviceArray,\n",
    "    targets: jnp.DeviceArray,\n",
    ") -> jnp.DeviceArray:\n",
    "    \"\"\"Categorical cross entropy?\"\"\"\n",
    "    return -jnp.mean(predict(params, images) * targets)\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def update(\n",
    "    params: List[Tuple[jnp.DeviceArray]],\n",
    "    images: jnp.DeviceArray,\n",
    "    targets: jnp.DeviceArray,\n",
    "    learning_rate: float = 1e-3,\n",
    ") -> List[Tuple[jnp.DeviceArray]]:\n",
    "    grads = jax.grad(loss)(params, images, targets)\n",
    "    return [\n",
    "        (\n",
    "            # updated weight\n",
    "            w - learning_rate * dw,\n",
    "            # updated bias\n",
    "            b - learning_rate * db,\n",
    "        )\n",
    "        for (w, b), (dw, db) in zip(params, grads)\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "DATA_DIR = \"/tmp/tfds\"\n",
    "\n",
    "# Load the full MNIST dataset\n",
    "mnist_data, info = tfds.load(\n",
    "    name=\"mnist\", batch_size=-1, data_dir=DATA_DIR, with_info=True\n",
    ")\n",
    "mnist_data = tfds.as_numpy(mnist_data)\n",
    "train_data = mnist_data[\"train\"]\n",
    "test_data = mnist_data[\"test\"]\n",
    "num_labels = info.features[\"label\"].num_classes\n",
    "h, w, c = info.features[\"image\"].shape\n",
    "num_pixels = h * w * c\n",
    "\n",
    "# Train dataset\n",
    "train_labels = train_data[\"label\"]\n",
    "train_labels = one_hot(train_labels, num_labels)\n",
    "train_images = train_data[\"image\"]\n",
    "train_images = jnp.reshape(train_images, (len(train_images), num_pixels))\n",
    "\n",
    "# Test dataset\n",
    "test_labels = test_data[\"label\"]\n",
    "test_labels = one_hot(test_labels, num_labels)\n",
    "test_images = test_data[\"image\"]\n",
    "test_images = jnp.reshape(test_images, (len(test_images), num_pixels))\n",
    "\n",
    "\n",
    "def get_train_batches():\n",
    "    \"\"\"Dataloader function returns batches of training data.\"\"\"\n",
    "    ds = tfds.load(name=\"mnist\", split=\"train\", as_supervised=True, data_dir=DATA_DIR)\n",
    "    ds = ds.batch(BATCH_SIZE).prefetch(1)\n",
    "    return tfds.as_numpy(ds)\n",
    "\n",
    "\n",
    "print(f\"Train: {train_images.shape}, {train_labels.shape}\")\n",
    "print(f\"Test: {test_images.shape}, {test_labels.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WANDB_PROJECT = \"minisweep\"\n",
    "\n",
    "# https://docs.wandb.ai/guides/sweeps/configuration\n",
    "sweep_config: Dict = {\n",
    "    \"method\": \"random\",\n",
    "    # \"method\": 'grid',\n",
    "    # \"method\": 'bayes',\n",
    "    \"metric\": {\n",
    "        \"name\": \"test_accuracy\",\n",
    "        \"goal\": \"maximize\",\n",
    "    },\n",
    "    \"parameters\": {\n",
    "        \"learning_rate\": {\n",
    "            \"distribution\": \"log_uniform\", #_values\",\n",
    "            \"min\": 1e-6,\n",
    "            \"max\": 1e-3,\n",
    "        },\n",
    "        \"layers\": {\n",
    "            \"values\": [\n",
    "                [128, 128, 10],\n",
    "                [784, 512, 512, 10],\n",
    "            ],\n",
    "        },\n",
    "        \"num_epochs\": {\n",
    "            \"distribution\": \"q_log_uniform\", #_values\",\n",
    "            \"q\": 1,\n",
    "            \"min\": 5,\n",
    "            \"max\": 30,\n",
    "        },\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE: int = 128\n",
    "N_TARGETS: int = 10\n",
    "\n",
    "\n",
    "def train(config: Dict = None):\n",
    "    \"\"\"Main training loop.\"\"\"\n",
    "    with wandb.init(project=WANDB_PROJECT, config=config):\n",
    "\n",
    "        params = init_network_params(config.layers, RANDOM_KEY)\n",
    "\n",
    "        # training loop\n",
    "        for epoch in range(config.num_epochs):\n",
    "            start_time = time.time()\n",
    "            for images, labels in get_train_batches():\n",
    "                images = jnp.reshape(images, (len(images), num_pixels))\n",
    "                labels = one_hot(labels, num_labels)\n",
    "                params = update(params, images, labels, learning_rate=config.learning_rate)\n",
    "            epoch_time = time.time()\n",
    "\n",
    "            # Re-calculating on entire dataset, this is super inneficient\n",
    "            train_accuracy = accuracy(params, train_images, train_labels)\n",
    "            test_accuracy = accuracy(params, test_images, test_labels)\n",
    "            wandb.log(\n",
    "                {\n",
    "                    \"epoch\": epoch,\n",
    "                    \"start_time\": start_time,\n",
    "                    \"duration\": epoch_time - start_time,\n",
    "                    \"train_accuracy\": train_accuracy,\n",
    "                    \"test_accuracy\": test_accuracy,\n",
    "                }\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=WANDB_PROJECT)\n",
    "wandb.agent(sweep_id, train, count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ea2824539c52f4c10c4fe96b333993739af7f74afbe81d7da2919ec10f2757c0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('minisweep')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
