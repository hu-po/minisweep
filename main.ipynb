{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Tuple, List, Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "# predictably random behavior\n",
    "RANDOM_KEY = jax.random.PRNGKey(42)\n",
    "\n",
    "# what is this being run on?\n",
    "print(f'jax.device_count() {jax.device_count()}')\n",
    "print(f'jax.local_device_count() {jax.local_device_count()}')\n",
    "for i, device in enumerate(jax.devices()):\n",
    "    print(f' --- Found device: {i} ')\n",
    "    print(f'\\t device_kind: {device.device_kind}')\n",
    "    print(f'\\t platform: {device.platform}')\n",
    "    print(f'\\t host_id: {device.host_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_layer_params(\n",
    "        input_size: int,\n",
    "        output_size: int,\n",
    "        random_key: jnp.DeviceArray,\n",
    "        scale: float = 1e-2) -> Tuple[jnp.DeviceArray]:\n",
    "    \"\"\" Creates a single layer of an MLP. \"\"\"\n",
    "    w_key, b_key = jax.random.split(random_key)\n",
    "    return scale * jax.random.normal(\n",
    "        w_key, (output_size, input_size)\n",
    "    ), scale * jax.random.normal(\n",
    "        b_key, (output_size,))\n",
    "\n",
    "\n",
    "def init_network_params(\n",
    "        layer_sizes: List[int],\n",
    "        random_key: jnp.DeviceArray) -> List[Tuple[jnp.DeviceArray]]:\n",
    "    \"\"\" Initialize a N-layer MLP. \"\"\"\n",
    "    layer_keys = jax.random.split(random_key, len(layer_sizes))\n",
    "    network_params: List[Tuple[jnp.DeviceArray]] = []\n",
    "    for in_size, out_size, key in zip(layer_sizes[:-1], layer_sizes[1:], layer_keys):\n",
    "        network_params.append(random_layer_params(in_size, out_size, key))\n",
    "    return network_params\n",
    "\n",
    "def relu(x: jnp.DeviceArray) -> jnp.DeviceArray:\n",
    "    \"\"\" Rectified-Linear Unit. \"\"\"\n",
    "    return jnp.maximum(0, x)\n",
    "\n",
    "def predict(\n",
    "    params: List[Tuple[jnp.DeviceArray]],\n",
    "    image: jnp.DeviceArray,\n",
    ") -> jnp.DeviceArray:\n",
    "    \"\"\" Forward prediction with an MLP denoted by params. \"\"\"\n",
    "    x: jnp.DeviceArray = image\n",
    "    for w, b in params[:-1]:\n",
    "        x = relu(jnp.dot(w, x) + b)\n",
    "    # last layer has no activation\n",
    "    last_w, last_b = params[-1]\n",
    "    x = relu(jnp.dot(last_w, x) + last_b)\n",
    "    # log of the sum of exponentials of input elements\n",
    "    return x - jax.scipy.special.logsumexp(x)\n",
    "\n",
    "def one_hot(\n",
    "    x: jnp.DeviceArray,\n",
    "    k: int,\n",
    "    dtype=jnp.float32,\n",
    ") -> jnp.DeviceArray:\n",
    "    \"\"\" One-hot encoding of size k. \"\"\"\n",
    "    return jnp.array(x[:, None] == jnp.arange(k), dtype)\n",
    "\n",
    "\n",
    "def accuracy(\n",
    "    params: List[Tuple[jnp.DeviceArray]],\n",
    "    images: jnp.DeviceArray,\n",
    "    targets: jnp.DeviceArray,\n",
    ") -> jnp.DeviceArray:\n",
    "    \"\"\" Accuracy of one-hot image prediction compared to target. \"\"\"\n",
    "    target_class = jnp.argmax(targets, axis=1)\n",
    "    predict_class = jnp.argmax(batched_predict(params, images), axis=1)\n",
    "    return jnp.mean(predict_class == target_class)\n",
    "\n",
    "\n",
    "def loss(\n",
    "    params: List[Tuple[jnp.DeviceArray]],\n",
    "    images: jnp.DeviceArray,\n",
    "    targets: jnp.DeviceArray,\n",
    ") -> jnp.DeviceArray:\n",
    "    \"\"\" Categorical cross entropy? \"\"\"\n",
    "    return -jnp.mean(batched_predict(params, images) * targets)\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def update(\n",
    "    params: List[Tuple[jnp.DeviceArray]],\n",
    "    images: jnp.DeviceArray,\n",
    "    targets: jnp.DeviceArray,\n",
    ") -> List[Tuple[jnp.DeviceArray]]:\n",
    "    grads = jax.grad(loss)(params, images, targets)\n",
    "    return [\n",
    "        (\n",
    "            # updated weight\n",
    "            w - STEP_SIZE*dw,\n",
    "            # updated bias\n",
    "            b - STEP_SIZE*db\n",
    "        ) for (w, b), (dw, db) in zip(params, grads)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "LAYERS = [784, 512, 512, 10]\n",
    "STEP_SIZE = 0.01\n",
    "NUM_EPOCHS = 10\n",
    "BATCH_SIZE = 128\n",
    "N_TARGETS = 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = init_network_params(LAYERS, RANDOM_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA_DIR = '/tmp/tfds'\n",
    "\n",
    "# Load the full MNIST dataset\n",
    "mnist_data, info = tfds.load(name='mnist', batch_size=-1, data_dir=DATA_DIR, with_info=True)\n",
    "mnist_data = tfds.as_numpy(mnist_data)\n",
    "train_data = mnist_data['train']\n",
    "test_data = mnist_data['test']\n",
    "num_labels = info.features['label'].num_classes\n",
    "h, w, c = info.features['image'].shape\n",
    "num_pixels = h * w * c\n",
    "\n",
    "# Train dataset\n",
    "train_labels = train_data['label']\n",
    "train_labels = one_hot(train_labels, num_labels)\n",
    "train_images = train_data['image']\n",
    "train_images = jnp.reshape(train_images, (len(train_images), num_pixels))\n",
    "\n",
    "# Test dataset\n",
    "test_labels = test_data['label']\n",
    "test_labels = one_hot(test_labels, num_labels)\n",
    "test_images = test_data['image']\n",
    "test_images = jnp.reshape(test_images, (len(test_images), num_pixels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Train: {train_images.shape}, {train_labels.shape}')\n",
    "print(f'Test: {test_images.shape}, {test_labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def get_train_batches():\n",
    "    \"\"\" Dataloader function returns batches of training data. \"\"\"\n",
    "    ds = tfds.load(name='mnist', split='train', as_supervised=True, data_dir=DATA_DIR)\n",
    "    ds = ds.batch(BATCH_SIZE).prefetch(1)\n",
    "    return tfds.as_numpy(ds)\n",
    "\n",
    "# training loop\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    for images, labels in get_train_batches():\n",
    "        images = jnp.reshape(images, (len(images), num_pixels))\n",
    "        labels = one_hot(labels, num_labels)\n",
    "        params = update(params, images, labels)\n",
    "    epoch_time = time.time()\n",
    "    \n",
    "    # Re-calculating on entire dataset, this is super inneficient\n",
    "    train_accuracy = accuracy(params, train_images, train_labels)\n",
    "    test_accuracy = accuracy(params, test_images, test_labels)\n",
    "    print(f'Epoch {epoch} started at {start_time}, total duration {epoch_time - start_time}')\n",
    "    print(f'\\t train accuracy {train_accuracy}')\n",
    "    print(f'\\t test accuracy {test_accuracy}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ea2824539c52f4c10c4fe96b333993739af7f74afbe81d7da2919ec10f2757c0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('minisweep')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
